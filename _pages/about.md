---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Wei Han is now a research scientist. His research interests now focus on a broad range of topics regarding multimodal large language models (LLMs), including but not limited to: **supervised fintuning (SFT), reinforcement learning algorithms, retrive-augmented generation, long-context modeling, mathematical reasoning** and **multimodal LLMs**. In the past, I also worked on video understanding, multimodal representation learning and semi-supervised learning. For more information, you can check this [CV](https://Clement25.github.io/files/CV.pdf).

Collaborations are always welcome! If you are looking forward to research experience or trying academic projects with me, feel free to drop me an email (better to attach your CV or personal website so that I can get to know you well). 

<span style="color: red;"> I am actively seeking research scientist/engineer positions starting in 2025 based in Singapore/China/U.S (no particular preference). Feel free to reach out to me if you are interested in my profile and my skill set meets the position requirements! </span>

## News
ðŸ”¥ðŸ”¥ðŸ”¥  <span style="color:red"> **[2025.01]** </span> Our work on multimodal recommendation has been accepeted to **NAACL 2025**.

Check out the project ðŸ‘‰ &emsp; ðŸ’» [code](https://github.com/declare-lab/Sealing) &ensp; ðŸ“– [paper](https://arxiv.org/pdf/2505.01255)


ðŸ”¥ðŸ”¥ðŸ”¥ <span style="color:red"> **[2024.10]** </span> **We release the latest work on *long-context modeling*, in which we propose a new architecture for efficient post-training and finetuning.**

Check out the project ðŸ‘‰ &emsp; ðŸ’» [code](https://github.com/Clement25/SharedLLM) &ensp; ðŸ“– [paper](https://arxiv.org/pdf/2410.19318)


[2024.03] Our work on efficient sampling in video question answering has been accepeted to **NAACL 2024**.

Check out the project ðŸ‘‰ &emsp; ðŸ’» [code](https://github.com/declare-lab/Sealing) &ensp; ðŸ“– [paper](https://arxiv.org/pdf/2307.04192.pdf)

[2024.02] We have released the code of **Auto Scaling**, the first framework for automatic instruction scaling in (multimodal) instruction fine-tuning.

Check out the project ðŸ‘‰ &emsp; ðŸ’» [code](https://github.com/declare-lab/Auto-Scaling) &ensp; ðŸ“– [paper](https://arxiv.org/pdf/2402.14492.pdf)

[2022.10] Two papers are accpeted to EMNLP and Findings of EMNLP 2022!
